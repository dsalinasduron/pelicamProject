\documentclass{article}
\usepackage{times}
\begin{document} 
\title{\LARGE{\textbf{dear diary}}}
\author{ali}
\maketitle
\newpage
\tableofcontents
\newpage

\section{6/14/2019}
for the first log lets go over what I did overall til now.
I looked at "Train your first neural network"
tried doing it on vscode but tensorflow didnt work and in my attempts to fix it by changing python version, 
I somehow managed to totally fuck it up and now I have bigger problems.
I started watching the google machine learning video. Im half way through so Im gonna talk more about that in the next commit ( tomorrow or sunday).
I also started looking at some latex tutorials. it seems to be too much work just to make a pdf file.
I don't like github as much as others but its a major tool so I better get used to it. every single time i go on it it feels like a new experience cuz i forget everything every time.
I feel a little scared and maybe overwhelmed but it be like that sometimes. its just the beginning.
(you will probably find alot of mistakes (grammatical or verbal) in my logs because grammarly does not work on vscode)

\section{6/17/2019}
today I completed the google ML crash course to the end of "First Steps with TF".
I already had an idea what they were talking about because of my statistical modeling class. So the material was not entirely new to me. 
It all went well up to the last section. I opened the exercise for TensorFlow and went through half of it before the code stopped working.
It just refused to acknowledge the previous work it had done itself and just gave me errors. Even when refreshed the page and did it all again.
But anyway. It was cool and now I’m really interested in doing the rest of the tutorial and see what it says.

\section{6/18/2019}
today started with me trying to find a document or a video on YouTube about functors that could actually understand. I found a 1hr video of a guy who was explaining what a functor is and what is its significance. But the level of complexity was too high for me. But then I found another video by the same guy on functors in programming which intrigued me. So now I want to go and watch the first video again and try to understand and then watch the “functors in programming”.
I also read a paper about a group of researchers that like us had cameras taking pictures of animals. But we want a machine learning algorithm that counts the number of animals in a picture but their machine learning algorithms only recognizes an animal in a picture. But still we could look at what they done and learn from it. Like I am now responsible to do some research on resnet 18 architecture and see if we can use it.
But there has to be more papers and research done that is close to what we are doing. We just have to search for it.

\section{6/19/19}
I did research on resnets especially resnet 18. It seems like an extra step that you can put on a CNN that makes it a little more efficient but does not make it anymore mathematically intensive. I think if we find out how exactly we can implement it and if we have the time to do so, we should. because it doesn't seem to have any drawbacks.

\section{6/20/19}
today we met with Jonas's team. I still don't understand what they want to do and what is their purpose. but they want to help us and I’m cool with that.

\section{6/21/19}
today I started working on the machine learning tutorial that Emily talked about. there is some inconsistency between Jonas was talking about and what’s on the website. the concepts are explained pretty well but the code is really messy and there is no straightforward walkthrough for the code.

\section{6/24/19}
I gave ML tutorial another code another shot and made some progress, but I think there is a very basic problem with the code that wants to access parts of pytorch that are not implemented. I’m not sure if the tutorial is actually up to date.

\section{6/25/19}
in the meeting we discussed the tutorial I went through and apparently Emily has the same issue as me. So I guess I’m not the only one. I will however start doing some more research more specifically on the topic of object detection. and make sure it can detect more than 1 object on a frame.

\section{6/26/19}
I found some interesting stuff called R-CNN, Fast R-CNN and Faster R-CNN. seems like it does exactly what we want but it is not as clear to me how it does so. this is some really intense stuff.

\section{6/27/19}
nothing much going on. just another meeting. but turns out Calvin is doing exactly what I wanted to do. I think he is working on R-CNNs too. I will jump on that ship and start looking for stuff I can code which are related to object detection.

\section{6/28/19}
as of right now I haven’t done much. I am just logging my hours and writing what was missing from my journal. But I will start looking at tutorials and papers and GitHub repositories to understand how a R-CNN architecture looks like and works.

\section{7/1/19}
I continue to read the website explaining the basics of R-CNN, Fast R-CNN and Faster R-CNN which then goes in depth on explaining the benefits and down sides of using each and compares them. I also started the coding part. It doesn’t seem like there is much I have to do I downloaded the basic Faster R-CNN files from a GitHub repository, and I have to parse the data into the correct format in order to feed into the code. But that is the problem I didn’t think I would encounter. I don’t know how to turn xml files to csv.

\section{7/2/19}
Today in the meeting I presented my lack of major progress in the coding section of the Faster R-CNN tutorial. Then I started looking into how to take data from a text file and multiple xml files and turn it into a csv file and started taking major steps. It was painful but I did it. 

\section{7/3/19}
More improvement on the coding side. I am close to running the code to let my laptop learn the pictures. Turns out the author of the blog is a true asshole. He made me take all the data and turn it into csv in order to later on turn the same csv and turn it into a text file. Again, very painful. I also attended a one of the summer undergraduate research programs talks. it was about grad school.

\section{7/4/19}
In the spirit of patriotism I refuse to work on the 4th of July. I will just sit on a couch and not drink beer cuz im 20 years old

\section{7/7/19}
I am ready to let my laptop learn the data. But there is another option too. the author has provided their learned weights so I will not train my laptop on anything. I will just take their weights and try it to see how it does. Spoiler alert. It does shit. It really underestimates how many red blood cells there are. And worse, it is confusing the red blood cells and white blood cells with each other

\section{7/8/19}
After the fuckup by the provided weights by the author I decided to run my own training code to give me my own weights. There are problems I have to solve like package versions and python versions again. And some changes to the code to find the correct folders but now the code is ready to run, and it is will take a shit load of time to finish.

\section{7/9/19}
I ran the training code for a bit last night, but it was too heavy, and I did not want to leave my laptop to be open and running all night so I quit the program. Today in the morning I ran it again and it finished the first of 500 epochs in the middle of the meeting, 5 hours after I started the training. The weights came in and I tried it. It seems way much better that the dude’s weights. It can identify all the red blood cells does not mess the labels.

\section{7/10/19}
Today I changes the codes so after running it gives me a text file showing the object counts for each of the pictures. And I also created a code to parse the real results of the testing pictures from xml to text file to show the real count of the cells. Seems like my code is overestimating the number of blood cells by about 7 or 8. Am not impressed

\section{7/11/19}
in the meeting I showcase my results and the comparison and we talk about how we can improve it. maybe change the CNN levels a bit. I should not run the code on my own laptop either because it the gpu sucks and takes way longer than it should to run a code.

\section{7/15/19}
I go head first into my code in order to simplify some of the training process so it does it faster. But problem is there is so much code and the variable names are not clear and almost no comments explaining whats in the code. So I start reading through to understand the code and put my own comments in there.

\section{7/16/19}
believe it or not, I am still trying to put comments in the code

\section{7/17/19, 7/18/19, 7/19/19}
in all these day I continued to make the code simpler and more understandable while not making too many drastic changes that makes the code to crash.

\section{7/22/19}
I gave up on fiddling with my code and now I am looking for good and accurate data for the training. That is I downloaded about 230 pictures from the server from the CamG and put them in folder and make proper files and will try to label them tomorrow.

\section{7/23/19}
I started labeling the pictures I have ad boy oh boy it is alot. most of the pictures have over 20 pelicans and seagulls combined and I only managed to go through about 100 of them today in our meeting.

\section{7/24/19}
well I continued to labeling my pictures but after talking on the group call, I guess we have different plan now. I will wait for calvin to put up his code and I will put in the propper scripts to get the creation date from each picture and spit it out with the results of the test. 

\section{7/25/19}
well i haven't done it as of yet but, I will first have to find where calvin has put his files and then do it. I guess it will take a few hours to finetune it so the output looks clean.



\end{document}